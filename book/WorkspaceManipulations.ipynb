{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workspace Manipulations\n",
    "\n",
    "In this chapter, you will learn about various workspace manipulations including how to convert from HistFactory XML+ROOT workspaces to pyhf. We'll cover some common pitfalls such as locations of root files, and being able to set the base path for the conversion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the XML+ROOT\n",
    "\n",
    "Note, getting the XML+ROOT won't necessarily be covered as part of the tutorial as it requires ROOT (though ROOT is installed in the Binder instance).\n",
    "\n",
    "If you want to practice extracting out the HistFactory files from the workspace, first create the workspace like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to be in the directory containing config directory\n",
    "from os import chdir\n",
    "from pathlib import Path\n",
    "\n",
    "_top_level_dir = Path.cwd()\n",
    "chdir(_top_level_dir.joinpath(\"data\", \"multichannel_histfactory\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! hist2workspace config/example.xml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and you'll notice a few new files being made!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "$ ls -lhF results/\n",
    "total 136K\n",
    "-rw-r--r-- 1 jovyan jovyan 40K Nov  8 21:01 example_channel1_GaussExample_model.root\n",
    "-rw-r--r-- 1 jovyan jovyan 38K Nov  8 21:01 example_channel2_GaussExample_model.root\n",
    "-rw-r--r-- 1 jovyan jovyan 47K Nov  8 21:01 example_combined_GaussExample_model.root\n",
    "-rw-r--r-- 1 jovyan jovyan 503 Nov  8 21:01 example_GaussExample.root\n",
    "-rw-r--r-- 1 jovyan jovyan  26 Nov  8 21:01 example_results.table\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls -lhF results/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In particular, `example_combined_GaussExample_model.root` is the file that contains the `RooStats::HistFactory::Measurement` object:\n",
    "\n",
    "```\n",
    "$ root results/example_combined_GaussExample_model.root \n",
    "   ------------------------------------------------------------\n",
    "  | Welcome to ROOT 6.18/04                  https://root.cern |\n",
    "  |                               (c) 1995-2019, The ROOT Team |\n",
    "  | Built for macosx64 on Sep 11 2019, 15:38:23                |\n",
    "  | From tags/v6-18-04@v6-18-04                                |\n",
    "  | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |\n",
    "   ------------------------------------------------------------\n",
    "\n",
    "root [0] \n",
    "Attaching file results/example_combined_GaussExample_model.root as _file0...\n",
    "\n",
    "RooFit v3.60 -- Developed by Wouter Verkerke and David Kirkby \n",
    "                Copyright (C) 2000-2013 NIKHEF, University of California & Stanford University\n",
    "                All rights reserved, please read http://roofit.sourceforge.net/license.txt\n",
    "\n",
    "(TFile *) 0x7ffaa30d2130\n",
    "root [1] .ls\n",
    "TFile**\t\tresults/example_combined_GaussExample_model.root\t\n",
    " TFile*\t\tresults/example_combined_GaussExample_model.root\t\n",
    "  KEY: RooWorkspace\tcombined;1\tcombined\n",
    "  KEY: TProcessID\tProcessID0;1\te1e9272e-fddb-11ea-86b3-1556a8c0beef\n",
    "  KEY: TDirectoryFile\tchannel1_hists;1\tchannel1_hists\n",
    "  KEY: TDirectoryFile\tchannel2_hists;1\tchannel2_hists\n",
    "  KEY: RooStats::HistFactory::Measurement\tGaussExample;1\n",
    "```\n",
    "\n",
    "from which you can extract out the necessary XML files as well:\n",
    "\n",
    "```\n",
    "root [2] GaussExample->PrintXML()\n",
    "Printing XML Files for measurement: GaussExample\n",
    "Printing XML Files for channel: channel1\n",
    "Finished printing XML files\n",
    "Printing XML Files for channel: channel2\n",
    "Finished printing XML files\n",
    "Finished printing XML files\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do this programatically, you can either write a `ROOT` macro\n",
    "\n",
    "```C++\n",
    "// printXML.C\n",
    "int printXML() {\n",
    "    TFile* _file0 = TFile::Open(\"results/example_combined_GaussExample_model.root\");\n",
    "    _file0->Get<RooStats::HistFactory::Measurement>(\"GaussExample\")->PrintXML();\n",
    "\n",
    "    return 0;\n",
    "}\n",
    "```\n",
    "\n",
    "and run it\n",
    "\n",
    "```console\n",
    "$ root -l -b -q printXML.C\n",
    "```\n",
    "\n",
    "but we can also do the same with PyROOT in as many lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ROOT\n",
    "\n",
    "_file0 = ROOT.TFile.Open(\"results/example_combined_GaussExample_model.root\")\n",
    "_file0.GaussExample.PrintXML()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which dumps them into the same directory you ran from:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "$ ls -lhF\n",
    "total 24K\n",
    "drwxr-xr-x 2 jovyan jovyan 4.0K Nov  8 19:52 config/\n",
    "drwxr-xr-x 2 jovyan jovyan 4.0K Nov  8 19:52 data/\n",
    "-rw-r--r-- 1 jovyan jovyan 1.1K Nov  8 21:01 GaussExample_channel1.xml\n",
    "-rw-r--r-- 1 jovyan jovyan  794 Nov  8 21:01 GaussExample_channel2.xml\n",
    "-rw-r--r-- 1 jovyan jovyan  459 Nov  8 21:01 GaussExample.xml\n",
    "drwxr-xr-x 2 jovyan jovyan 4.0K Nov  8 21:01 results/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls -lhF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chdir(_top_level_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XML to JSON\n",
    "\n",
    "### via the command line\n",
    "\n",
    "So pyhf comes with a lot of nifty utilities you can access. The documentation for the command line can be found via `pyhf --help` or [online](https://pyhf.readthedocs.io/en/v0.7.3/cli.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pyhf --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's focus for now on `pyhf xml2json` which requires that you have installed `pyhf[xmlio]` (pyhf with the xmlio option).\n",
    "\n",
    "```\n",
    "python -m pip install pyhf[xmlio]\n",
    "```\n",
    "\n",
    "Again, the online documentation for this option is found [here](https://pyhf.readthedocs.io/en/v0.7.3/cli.html#pyhf-xml2json)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pyhf xml2json --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's remind ourselves of what the top-level XML file looks like, as this is the `ENTRYPOINT_XML`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! tail -n +15 data/multichannel_histfactory/config/example.xml | cat -n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So to explain these options:\n",
    "* `basedir` specifies the base directory for where all the XML files are reference with respect to. As you can see from lines 3, 4, 5 - this should be the directory containing `results/` and `config/`\n",
    "* `output-file` specifies the output JSON file. If one is not specified, this will print to the screen, which you can redirect into a file if you want (`pyhf xml2json ... > workspace.json`)\n",
    "* `hide-progress` will disable showing the progress bars when running the script... but we like progress bars ðŸ™‚\n",
    "\n",
    "Let's go ahead and run this command, but we won't specify the output file so it goes to the screen. We'll also disable the progress tracking, just so we have a nicer output for this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pyhf xml2json --basedir data/multichannel_histfactory data/multichannel_histfactory/config/example.xml --hide-progress | cat -n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 130 lines for the entire workspace! Not too shabby. If we look through a couple of pieces:\n",
    "* line 2: specify a list of channels\n",
    "* line 5: specify the samples for `channel1`\n",
    "* lines 6-10: specify the expected event rate for the `signal` sample in `channel1`\n",
    "* line 11: specify a list of modifiers (e.g. parameters that modify the sample)\n",
    "\n",
    "Similarly, if we continue down to the second half of this JSON, we hit line 72 which specifies a list of `measurements` for this workspace. In fact, we only have one measurement called `GaussExample` with the parameter of interest defined as `SigXsecOverSM`. This measurement also specifies additional parameter configuration such as details for the luminosity modifier (parameter name `lumi`).\n",
    "\n",
    "Nearly at the end, the next part of this specification is for the `observations` (observed data) on line 113. Each observation corresponds with the channel, where `channel1` has two bins, and `channel2` also has two bins.\n",
    "\n",
    "Finally, we have a `version` which specifies the version of the schema used for the JSON HistFactory. In this case, we're using `1.0.0` which has the [https://pyhf.readthedocs.io/en/v0.7.3/schemas/1.0.0/workspace.json](https://pyhf.readthedocs.io/en/v0.7.3/schemas/1.0.0/workspace.json) definition which refers to the [https://pyhf.readthedocs.io/en/v0.7.3/schemas/1.0.0/defs.json](https://pyhf.readthedocs.io/en/v0.7.3/schemas/1.0.0/defs.json).\n",
    "\n",
    "What's really nice about the schema definition is that it allows anyone to write their own tooling/scripting to build up the workspace and quickly check if it matches the schema. This will get you 90% of the way there in having a valid workspace to work with.\n",
    "\n",
    "There are some additional checks that cannot be done, such as name conflicts, or ensuring that all samples in a channel have the same binning structure. The good news is that these checks can be done simply by loading up the workspace into a `pyhf.Workspace` object which will do the schema validation, as well as the additional checks.\n",
    "\n",
    "Speaking of `pyhf.Workspace` objects...\n",
    "\n",
    "### via the python interface\n",
    "\n",
    "Let's do the exact same thing, but from the python interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyhf\n",
    "import pyhf.readxml  # not imported by default!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = pyhf.readxml.parse(\n",
    "    \"data/multichannel_histfactory/config/example.xml\", \"data/multichannel_histfactory\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we're not going to dump this out. We already did that above. Let's just quickly go ahead and load it into a [`pyhf.Workspace`](https://pyhf.readthedocs.io/en/v0.7.3/_generated/pyhf.workspace.Workspace.html#pyhf.workspace.Workspace) object because we can."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = pyhf.Workspace(spec)\n",
    "print(f\"    channels: {ws.channels}\")\n",
    "print(f\"       nbins: {ws.channel_nbins}\")\n",
    "print(f\"     samples: {ws.samples}\")\n",
    "print(f\"   modifiers: {ws.modifiers}\")\n",
    "print(f\"observations: {ws.observations}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Already, we're seeing a lot of information about this workspace as it's rather inspectable. Remember, this is not a model. What we call a 'model' is to combine the channel specification with a measurement... that is, a measurement of a workspace uniquely defines that model. A model might choose a particular parameter of interest to measure or set specific parameters as constant during the fit. These configurations are all stored in the `measurements` key we saw above. We'll explore more about models in the next chapter.\n",
    "\n",
    "Let's move on to more things we can do with the command line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workspace Inspection\n",
    "\n",
    "Now that we have a working command for converting our XML to JSON, let's go ahead and take advantage of the JSON output by piping it to `pyhf inspect` which will print out a nice summary of our workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pyhf inspect --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pyhf xml2json --basedir data/multichannel_histfactory data/multichannel_histfactory/config/example.xml --hide-progress | \\\n",
    "  pyhf inspect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Immediately, we get a lot of useful information. We can see the number of channels, samples, parameters, and modifiers. Then we get a breakdown of the channels (and the number of bins for each channel), the samples, and the parameters. Finally, we see a list of measurements defined in the workspace, as well as the `(*)` denoting the default measurement if one is not specified.\n",
    "\n",
    "**Could the number of parameters and modifiers differ?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Normalizing\" a Workspace\n",
    "\n",
    "There comes a time when you need to make comparisons to determine changes between two workspaces. This means depending on how the workspace is generated, one might need to \"sort\" it. `pyhf sort` is a utility that will normalize the workspace for you, such that certain operations like calculating a checksum (`pyhf digest`) guarantees unitarity.\n",
    "\n",
    "For simple workspaces like the ones we're using in this tutorial, they're already sorted... however, this is not true in the real world. Notice how the `bkg` is now the first sample and `signal` is the second sample after sorting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pyhf sort --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pyhf xml2json --basedir data/multichannel_histfactory data/multichannel_histfactory/config/example.xml --hide-progress | \\\n",
    "  pyhf sort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing a digest\n",
    "\n",
    "Next up is a way to determine if two workspaces are equivalent, simply by comparing their computed digest. Note that this is based on the contents of the workspace and will not ensure floating-point differences are treated identically. That is, `2.19999999` and `2.2000001` will likely be treated as differently in the digest calculation as in python. We'll show here why sorting is very important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pyhf digest --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pyhf xml2json --basedir data/multichannel_histfactory data/multichannel_histfactory/config/example.xml --hide-progress | \\\n",
    "  pyhf digest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pyhf xml2json --basedir data/multichannel_histfactory data/multichannel_histfactory/config/example.xml --hide-progress | \\\n",
    "  pyhf sort | \\\n",
    "  pyhf digest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that the ordering of the samples will have switched through the sorting.\n",
    "\n",
    "The `sha256` algorithm is used to compute the checksum for this workspace. This means that one can generally \"normalize\" all workspaces, then compute the digest and guarantee uniqueness. As with all command line functionality you've seen so far, there are equivalent ways to do it through python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Unsorted: {pyhf.utils.digest(ws)}\")\n",
    "print(f\"Sorted:   {pyhf.utils.digest(pyhf.Workspace.sorted(ws))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Pruning\" away items\n",
    "\n",
    "Sometimes you want to manipulate workspaces by removing channels or samples or systematics (or measurements). This can be useful when trying to debug fits, or to build background-only workspaces, or to clean up a workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pyhf prune --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prune channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! pyhf xml2json --basedir data/multichannel_histfactory data/multichannel_histfactory/config/example.xml --hide-progress | \\\n",
    "  pyhf prune -c channel1 | \\\n",
    "  pyhf inspect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prune samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pyhf xml2json --basedir data/multichannel_histfactory data/multichannel_histfactory/config/example.xml --hide-progress | \\\n",
    "  pyhf prune -s signal | \\\n",
    "  pyhf inspect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prune modifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! pyhf xml2json --basedir data/multichannel_histfactory data/multichannel_histfactory/config/example.xml --hide-progress | \\\n",
    "  pyhf prune -m uncorrshape_signal | \\\n",
    "  pyhf inspect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prune modifier types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pyhf xml2json --basedir data/multichannel_histfactory data/multichannel_histfactory/config/example.xml --hide-progress | \\\n",
    "  pyhf prune -t shapesys | \\\n",
    "  pyhf inspect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Renaming items\n",
    "\n",
    "In addition to removing items, you might want to rename your channels, samples, modifiers, or measurement names. This can be useful for creating modifier correlations, or removing modifier correlations, or just cleaning up your workspace to get it ready for publication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! pyhf rename --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rename channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! pyhf xml2json --basedir data/multichannel_histfactory data/multichannel_histfactory/config/example.xml --hide-progress | \\\n",
    "  pyhf rename -c channel1 SR -c channel2 CR | \\\n",
    "  pyhf inspect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rename samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pyhf xml2json --basedir data/multichannel_histfactory data/multichannel_histfactory/config/example.xml --hide-progress | \\\n",
    "  pyhf rename -s bkg background | \\\n",
    "  pyhf inspect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rename modifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! pyhf xml2json --basedir data/multichannel_histfactory data/multichannel_histfactory/config/example.xml --hide-progress | \\\n",
    "  pyhf rename -m uncorrshape_signal corrshape -m uncorrshape_control corrshape | \\\n",
    "  pyhf inspect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rename measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pyhf xml2json --basedir data/multichannel_histfactory data/multichannel_histfactory/config/example.xml --hide-progress | \\\n",
    "  pyhf rename --measurement GaussExample FitConfig | \\\n",
    "  pyhf inspect"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
