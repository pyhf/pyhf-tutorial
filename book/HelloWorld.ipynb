{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My First Likelihood\n",
    "\n",
    "ðŸŽ¶ I'm the very Model of a simple HEP-like measurement... ðŸŽ¶\n",
    "\n",
    "## HEP-like?\n",
    "\n",
    "So what do we do as experimentalists in High Energy Physics? We have a gigantic detector that serves as a counting machine for physics. We smash particles and take pictures of the aftermath. Then we propose hypotheses for new physics that we want to test using this data. So we will have, at the very least:\n",
    "\n",
    "* signal\n",
    "* background (with some uncertainty)\n",
    "* some observations\n",
    "\n",
    "This is probably the simplest model one could use in HistFactory... so let's make it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pyhf\n",
    "from pyhf.contrib.viz import brazil  # not imported by default!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pyhf.simplemodels.hepdata_like(\n",
    "    signal_data=[5.0, 10.0], bkg_data=[50.0, 60.0], bkg_uncerts=[5.0, 12.0]\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What did we just make? This returns a [`pyhf.Model`](https://pyhf.readthedocs.io/en/v0.6.0/_generated/pyhf.pdf.Model.html#pyhf.pdf.Model) object. Let's check out the specification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(model.spec, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the specification, we defined a single two-bin channel ('singlechannel') with two samples: a **signal sample** and a **background sample**. The signal sample has an _unconstrained normalization factor_ $\\mu$, the signal strength, while the background sample carries an _uncorrelated shape systematic_ controlled by parameters $\\gamma_{1}$ and $\\gamma_{2}$. The _background uncertainty_ for the bins is $10\\%$ and $20\\%$ respectively.\n",
    "\n",
    "These uncertainties are **absolute** (not relative!). We have 10% and 20% relative uncertainty for the bins in the background sample respectively.\n",
    "\n",
    "(*Note: we have a workspace defined with this simple model in `data/2-bin_1-channel.json` which we will look at later.*)\n",
    "\n",
    "Let's explore the model a little bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"  channels: {model.config.channels}\")\n",
    "print(f\"     nbins: {model.config.channel_nbins}\")\n",
    "print(f\"   samples: {model.config.samples}\")\n",
    "print(f\" modifiers: {model.config.modifiers}\")\n",
    "print(f\"parameters: {model.config.parameters}\")\n",
    "print(f\"  nauxdata: {model.config.nauxdata}\")\n",
    "print(f\"   auxdata: {model.config.auxdata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxiliary Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whoa, hold up! What's with the auxiliary data? Recall the HistFactory definition\n",
    "\n",
    "$$\n",
    "p(n,a|\\theta) = \\underbrace{\\prod_{\\mathrm{channel}\\ c}\\prod_{\\mathrm{bin}\\ b} \\mathrm{Pois}(n_{cb} | \\lambda_{cb}(\\theta))}_{\\text{main}} \\underbrace{\\prod_{\\mathrm{constraint}\\ \\chi} p_\\chi(a_\\chi | \\chi)}_{\\text{auxiliary}} \\qquad \\lambda_{cb}(\\theta) = \\sum_{\\mathrm{sample}\\ s} \\lambda_{cbs}(\\theta)\n",
    "$$\n",
    "\n",
    "and the auxiliary data here is passed into a constraint function? There's two things going on here:\n",
    "\n",
    "1. the uncorrelated shapesys modifier is constrained by a Poisson\n",
    "2. the auxiliary data is fully determined by the shapesys 'data' and the 'background' data\n",
    "\n",
    "So if we were to explicitly write out the likelihood we were seeing symbolically, it would be:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "p_\\text{main} \\cdot p_\\text{aux} &= \\text{Pois}(n | \\lambda) \\cdot p_\\text{aux}\\\\\n",
    "                                 &= \\text{Pois}(n | \\mu s + \\gamma b) \\cdot p_\\text{aux}\\\\\n",
    "                                 &= \\text{Pois}(n | \\mu s + \\gamma b) \\cdot \\text{Pois}(n_\\text{aux} = (b/\\delta b)^2 | \\mu = (b/\\delta b)^2 \\gamma )\\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where $n = \\{n_1, n_2\\}$ for a 2-bin model (we're being slightly fast and loose with our mathematical notation here), and similarly for $s$, $b$, and $\\gamma$.\n",
    "\n",
    "The 'shapesys' is defined in the [HistFactory paper](https://cds.cern.ch/record/1456844)... however, it can be a little hard to extract out the necessary information. We've provided a nice table of [Modifiers and Constraints](https://pyhf.readthedocs.io/en/v0.6.0/intro.html#id24) in the introduction of our pyhf documentation to use as reference.\n",
    "\n",
    "![modifiers and constraints](assets/modifiers_and_constraints.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the first row here which is our uncorrelated shape modifier. This is a multiplicative modifier denoted by $\\kappa$ per-bin (denoted by $\\gamma_b$). Notice that the input for the constraint term requires $\\sigma_b$ which is the relative uncertainty of that modifier. This is Poisson-constrained by $\\sigma_b^{-2}$. Let's quickly verify by hand to convince ourselves of what's going on here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.array([5.0, 12.0]) / np.array([50.0, 60.0])) ** -2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.auxdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whew. Ok, I guess that makes sense.\n",
    "\n",
    "## Data and Parameters\n",
    "\n",
    "What about the actual data for the model then?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [],
   "source": [
    "model.expected_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hrmm, that didn't work. It seems we need to specify the parameter values to get the data for the model at those parameter values. Well, we know the default for $\\mu=1$ and $\\gamma = 1$. Also recall that the uncorrelated shape allocates a parameter per bin, so our model has **3 parameters** with **2 modifiers**. So let's just try that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.expected_data([1.0, 1.0, 1.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This returns the data for the entire likelihood, the main model as well as the constraint (or auxiliary) model. We can also drop the auxdata to get the actual data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.expected_data([1.0, 1.0, 1.0], include_auxdata=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, there are also methods separately for the actual data and the auxdata, both which take in all the parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.expected_actualdata([1.0, 1.0, 1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.expected_auxdata([1.0, 1.0, 1.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Parameter Ordering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So how do we know what these parameters correspond to? The way `pyhf` works under the hood, you can imagine an N-dimensional tensor that is purely bookkeeping all the different expected rates and modifications (read: systematics) involved that we can apply tensor algebra calculations to. This means that the ordering of the entries in each dimension is important, so we need to keep track of the order of the channels, the samples, the parameters. In `pyhf`, you can ask for the parameters or modifiers in a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.modifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, these might not necessarily correspond with the order of the parameters when we build this tensor internally, and we keep this order under a different variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.par_order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Parameter Multiplicity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But this clearly doesn't answer everything, because we were using three numbers assigned to two parameters! How does that work? Well, recall that the only channel in this model has 2 bins:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.channel_nbins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and one of the parameters (the uncorrelated shape systematic) will be configured by $\\gamma_b$ - that is, one parameter for each bin of the sample in that channel. How does `pyhf` know that the parameter set is associated with two parameters? We can ask for information about the `paramset`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.param_set(\"uncorr_bkguncrt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which we can see is constrained by a Poisson and"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.param_set(\"uncorr_bkguncrt\").n_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Parameter Defaults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So how do we know what we should set the parameters to? The nice thing is that this is up to you! The model will come with some suggested defaults for parameters..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.suggested_init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and their bounds..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.suggested_bounds()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and if the parameter should be held constant in a fit or not ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.suggested_fixed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So armed with this knowledge, we could have also done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_pars = model.config.suggested_init()\n",
    "model.expected_actualdata(init_pars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the expected actual data from the model (signal + background). We could turn off the signal, corresponding with the normalization factor. We just need to know the index of the parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.poi_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and then just change the parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bkg_pars = [*init_pars]  # my clever way to \"copy\" the list by value\n",
    "bkg_pars[model.config.poi_index] = 0\n",
    "model.expected_actualdata(bkg_pars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Inference\n",
    "\n",
    "The core of statistical analysis is the statistical model. For inference, it's viewed as a function of the parameters with the data fixed.\n",
    "\n",
    "$$\n",
    "\\log L(\\theta | x) = \\log p(x | \\theta)\n",
    "$$\n",
    "\n",
    "The value of the likelihood is a float. Let's try it for both the background-only model as well as the signal+background model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = [52.5, 65.0] + model.config.auxdata  # this is a common pattern!\n",
    "\n",
    "model.logpdf(pars=bkg_pars, data=observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.logpdf(pars=init_pars, data=observations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're not performing inference just yet. We're simply computing the 'logpdf' of the model specified by the parameters $\\theta$ against the provided data. To perform a fit, we use the [inference API](https://pyhf.readthedocs.io/en/v0.6.0/api.html#inference) via `pyhf.infer`.\n",
    "\n",
    "To fit a model to data, we usually want to find the $\\hat{\\theta}$ which refers to the \"Maximum Likelihood Estimate\". This is often referred to mathematically by\n",
    "\n",
    "$$\n",
    "\\hat{\\theta}_\\text{MLE} = \\text{argmax}_\\theta L(\\theta | x)\n",
    "$$\n",
    "\n",
    "Let's perform a fit on this model to the provided observations we just made up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyhf.infer.mle.fit(data=observations, pdf=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what can we say? With nominal signal `[5, 10]` and nominal background = `[50, 60]`, an observed count of `[52.5, 65]` suggests best fit values:\n",
    "* $\\hat{\\mu} \\approx 0.5$,\n",
    "* $\\hat{\\gamma} \\approx [1,1]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Hypothesis Testing\n",
    "\n",
    "Great, so we can fit. But that's not usually the interesting part, since we cannot make any statements about this. What we prefer to do is perform a hypothesis test to either:\n",
    "\n",
    "* reject Standard Model hypothesis - a discovery fit\n",
    "* reject Beyond the Standard Model hypothesis - an exclusion fit\n",
    "\n",
    "So we need to compute test statistics in order to evaluate the hypothesis. If we know the distribution of the test statistic under two different hypotheses, we can compute a [CLs](https://en.wikipedia.org/wiki/CLs_method_(particle_physics)) value. This is a modified pseudo-frequentist *p*-value.\n",
    "\n",
    "$$\n",
    "\\text{CL}_\\text{s} = \\frac{\\text{CL}_\\text{s+b}}{\\text{CL}_\\text{b}}\n",
    "$$\n",
    "\n",
    "with\n",
    "\n",
    "$$\n",
    "\\text{CL}_\\text{s+b} = \\int_{t_\\text{obs}}^\\infty \\text{d}t\\ p_0(t | H_0) \\qquad\\qquad \\text{CL}_\\text{b} = \\int_{t_\\text{obs}}^\\infty \\text{d}t\\ p_1(t | H_1)\n",
    "$$\n",
    "\n",
    "This is done by splitting the model parameters up into two groups:\n",
    "\n",
    "* parameters of interest (POI - can have multiple!)\n",
    "* nuisance parameters (NP)\n",
    "\n",
    "Recall that additionally, all parameters are either constrained or unconstrained. Parameters of interest happen to always be unconstrained parameters.\n",
    "\n",
    "$$\n",
    "    f(\\boldsymbol{x}|\\phi) = f(\\boldsymbol{x}|\\overbrace{\\eta}^{\\llap{\\text{free}}},\\underbrace{\\chi}_{\\llap{\\text{constrained}}}) = f(\\boldsymbol{x}|\\overbrace{\\psi}^{\\rlap{\\text{parameters of interest}}},\\underbrace{\\theta}_{\\rlap{\\text{nuisance parameters}}})\n",
    "$$\n",
    "\n",
    "In the vast majority of cases, the test statistic is the profile likelihood ratio, or variations of it:\n",
    "\n",
    "$$\n",
    "t_\\psi(x) = \\frac{L(\\psi, \\hat{\\hat{\\theta}})}{L({\\hat{\\psi}, \\hat{\\theta}})}\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "* $\\hat{\\hat{\\theta}}$ is the best fitted value of the nuisance parameters (for fixed POIs)\n",
    "* $\\hat{\\psi}$ and $\\hat{\\theta}$ are the best fitted values in a global fit\n",
    "\n",
    "So let's run a hypothesis test for\n",
    "\n",
    "* null hypothesis ($\\mu = 1$) - \"SUSY is real\"\n",
    "* alternate hypothesis ($\\mu = 0$) - \"Standard Model explains it all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLs_obs, CLs_exp = pyhf.infer.hypotest(\n",
    "    1.0,  # null hypothesis\n",
    "    [52.5, 65.0] + model.config.auxdata,\n",
    "    model,\n",
    "    test_stat=\"q\",\n",
    "    return_expected_set=True,\n",
    ")\n",
    "print(f\"      Observed CLs: {CLs_obs:.4f}\")\n",
    "for expected_value, n_sigma in zip(CLs_exp, np.arange(-2, 3)):\n",
    "    print(f\"Expected CLs({n_sigma:2d} Ïƒ): {expected_value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nicely enough, `pyhf` is smart enough to let us know that, if for a model where $\\hat{\\psi} < 0$, we're not going to be able to catch it because our default bounds were bounding the parameter of interest from below at 0. For more information, see Equation 14 in [[1007.1727]](https://arxiv.org/abs/1007.1727)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.suggested_bounds()[model.config.poi_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should heed the warning and switch our test statistic in this case to a variation of it $q_\\mu \\to \\tilde{q}_\\mu$. We could also change the bounds from the default to allow $\\mu$ to float below zero. In this case, we're just going to use a more appropriate test statistic as we know $\\hat{\\mu} \\geq 0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLs_obs, CLs_exp = pyhf.infer.hypotest(\n",
    "    1.0,  # null hypothesis\n",
    "    [52.5, 65.0] + model.config.auxdata,\n",
    "    model,\n",
    "    test_stat=\"qtilde\",\n",
    "    return_expected_set=True,\n",
    ")\n",
    "print(f\"      Observed CLs: {CLs_obs:.4f}\")\n",
    "for expected_value, n_sigma in zip(CLs_exp, np.arange(-2, 3)):\n",
    "    print(f\"Expected CLs({n_sigma:2d} Ïƒ): {expected_value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Upper Limit\n",
    "\n",
    "To get upper limits, we just need to run multiple hypothesis tests for a lot of different null hypotheses of BSM with $\\mu \\in [0, \\ldots, 5.0]$ and then find the value of $\\mu$ for which the null hypothesis is rejected (a 95% $\\text{CL}_\\text{s}$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poi_values = np.linspace(0.1, 5, 50)\n",
    "results = [\n",
    "    pyhf.infer.hypotest(\n",
    "        poi_value,\n",
    "        observations,\n",
    "        model,\n",
    "        test_stat=\"qtilde\",\n",
    "        return_expected_set=True,\n",
    "    )\n",
    "    for poi_value in poi_values\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this ran pretty fast. We can plot the \"standard Brazil band\" using the `pyhf.contrib` module (which needs `pyhf[contrib]`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(10.5, 7)\n",
    "ax.set_title(\"Hypothesis Tests\")\n",
    "ax.set_xlabel(r\"$\\mu$\")\n",
    "ax.set_ylabel(r\"$\\mathrm{CL}_{s}$\")\n",
    "\n",
    "brazil.plot_results(ax, poi_values, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then just calculate the upper limit by interpolating:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed = np.asarray([h[0] for h in results]).ravel()\n",
    "expected = np.asarray([h[1][2] for h in results]).ravel()\n",
    "print(f\"Upper limit (obs): Î¼ = {np.interp(0.05, observed[::-1], poi_values[::-1]):.4f}\")\n",
    "print(f\"Upper limit (exp): Î¼ = {np.interp(0.05, expected[::-1], poi_values[::-1]):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can also just use the [`upperlimit` API](https://pyhf.readthedocs.io/en/v0.6.0/_generated/pyhf.infer.intervals.upperlimit.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_limit, exp_limits, (scan, results) = pyhf.infer.intervals.upperlimit(\n",
    "    observations, model, poi_values, level=0.05, return_results=True\n",
    ")\n",
    "print(f\"Upper limit (obs): Î¼ = {obs_limit:.4f}\")\n",
    "print(f\"Upper limit (exp): Î¼ = {exp_limits[2]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
