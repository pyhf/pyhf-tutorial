{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making a Pull Plot\n",
    "\n",
    "Let's use a background-only workspace that we've bundled with the tutorial. It's a little bit more complicated than the simple workspace we've seen in the past, but it will be a bit easier to demonstrate the efficacy of pulls this way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "\n",
    "import pyhf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/bkg_only.json\") as serialized:\n",
    "    spec = json.load(serialized)\n",
    "\n",
    "workspace = pyhf.Workspace(spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = workspace.model(poi_name=None)  # background-only!\n",
    "data = workspace.data(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making a Pull Plot\n",
    "\n",
    "We need to use minuit in order to perform the fits. So first we'll set our backends to use numpy and minuit. Then we'll do a bunch of setup to make it easier to compute the pulls. Work is on-going in `pyhf` to streamline this a bit more and put it into `pyhf.contrib`.\n",
    "\n",
    "Unlike the `scipy` optimizer, `minuit` provides the uncertainties on the parameters which we need for the pulls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Tensor Lib: {pyhf.tensorlib}\")\n",
    "print(f\"Optimizer:  {pyhf.optimizer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyhf.set_backend(\"numpy\", \"minuit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Tensor Lib: {pyhf.tensorlib}\")\n",
    "print(f\"Optimizer:  {pyhf.optimizer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: one really nice feature that we love about the `backend` switching is you can also customize the backends instead of using a default config... such as changing the `tolerance`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyhf.optimizer.tolerance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyhf.set_backend(pyhf.tensorlib, pyhf.optimize.minuit_optimizer(tolerance=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Tensor Lib: {pyhf.tensorlib}\")\n",
    "print(f\"Optimizer:  {pyhf.optimizer}\")\n",
    "print(f\"Tolerance:  {pyhf.optimizer.tolerance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing the Fit\n",
    "\n",
    "In the past, we've done a hypothesis test which does multiple fits, both constrained and unconstrained fits. Instead, we will need to perform an unconstrained fit on the background in order to determine the fluctuation of all the parameters and the corresponding pulls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pyhf.infer.mle.fit(data, model, return_uncertainties=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `return_uncertainties=True`, we return, instead of just a 1-dimensional vector of the fitted parameter values, a 2-dimensional vector including the fitted parameter uncertainties as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let's split this up to handle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestfit, errors = result.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize to natural width\n",
    "\n",
    "Now we need to compute the pulls. In order to do so, we need to determine the constrained parameters of the model. We can do this by looping over the ordered parameters of the model. `pyhf` maintains a particular order of the parameters as we load them up into a large tensor in a specific order. So we can access this same order of the fitted parameters to the parameter names using `pyhf.Model.config.par_order`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.par_order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So first, we'll compute the pulls. This is done by calculating the difference between the fitted parameter value, the initial value, and divide by the width of that constrained parameter\n",
    "\n",
    "$$\n",
    "\\text{pull} = \\frac{\\hat{\\chi} - \\chi}{\\sigma}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pulls = pyhf.tensorlib.concatenate(\n",
    "    [\n",
    "        (bestfit[model.config.par_slice(k)] - model.config.param_set(k).suggested_init)\n",
    "        / model.config.param_set(k).width()\n",
    "        for k in model.config.par_order\n",
    "        if model.config.param_set(k).constrained\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also do this similarly for the error on the parameter as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pullerr = pyhf.tensorlib.concatenate(\n",
    "    [\n",
    "        errors[model.config.par_slice(k)] / model.config.param_set(k).width()\n",
    "        for k in model.config.par_order\n",
    "        if model.config.param_set(k).constrained\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we just need to create a set of labels for the parameters that were constrained that we are showing pulls for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.asarray(\n",
    "    [\n",
    "        f\"{k}[{i}]\" if model.config.param_set(k).n_parameters > 1 else k\n",
    "        for k in model.config.par_order\n",
    "        if model.config.param_set(k).constrained\n",
    "        for i in range(model.config.param_set(k).n_parameters)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Order Results\n",
    "\n",
    "Now we need to sort the labels in order of the uncertainty to make things easier to digest. We'll figure out the sort order we need using `np.argsort` and apply that ordering to everything we've created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_order = np.argsort(errors)\n",
    "bestfit = bestfit[_order]\n",
    "errors = errors[_order]\n",
    "labels = labels[_order]\n",
    "pulls = pulls[_order]\n",
    "pullerr = pullerr[_order]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Results\n",
    "\n",
    "Now we can finally make a plot to appease our supervisor!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(20, 5)\n",
    "\n",
    "# set up axes labeling, ranges, etc...\n",
    "ax.xaxis.set_major_locator(mticker.FixedLocator(np.arange(labels.size).tolist()))\n",
    "ax.set_xticklabels(labels, rotation=30, ha=\"right\")\n",
    "ax.set_xlim(-0.5, len(pulls) - 0.5)\n",
    "ax.set_title(\"Pull Plot\", fontsize=18)\n",
    "ax.set_ylabel(r\"$(\\theta - \\hat{\\theta})\\,/ \\Delta \\theta$\", fontsize=18)\n",
    "\n",
    "# draw the +/- 2.0 horizontal lines\n",
    "ax.hlines([-2, 2], -0.5, len(pulls) - 0.5, colors=\"black\", linestyles=\"dotted\")\n",
    "# draw the +/- 1.0 horizontal lines\n",
    "ax.hlines([-1, 1], -0.5, len(pulls) - 0.5, colors=\"black\", linestyles=\"dashdot\")\n",
    "# draw the +/- 2.0 sigma band\n",
    "ax.fill_between([-0.5, len(pulls) - 0.5], [-2, -2], [2, 2], facecolor=\"yellow\")\n",
    "# drawe the +/- 1.0 sigma band\n",
    "ax.fill_between([-0.5, len(pulls) - 0.5], [-1, -1], [1, 1], facecolor=\"green\")\n",
    "# draw a horizontal line at pull=0.0\n",
    "ax.hlines([0], -0.5, len(pulls) - 0.5, colors=\"black\", linestyles=\"dashed\")\n",
    "# finally draw the pulls\n",
    "ax.scatter(range(len(pulls)), pulls, color=\"black\")\n",
    "# and their uncertainties\n",
    "ax.errorbar(\n",
    "    range(len(pulls)),\n",
    "    pulls,\n",
    "    color=\"black\",\n",
    "    xerr=0,\n",
    "    yerr=pullerr,\n",
    "    marker=\".\",\n",
    "    fmt=\"none\",\n",
    ")\n",
    "\n",
    "# error > 1\n",
    "error_gt1 = np.argmax(errors > 1) - 0.5\n",
    "ax.axvline(x=error_gt1, color=\"red\", linestyle=\"--\")\n",
    "ax.text(\n",
    "    error_gt1 + 0.1, 1.5, r\"$\\sigma \\geq 1 \\longrightarrow$\", color=\"red\", fontsize=18\n",
    ");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
